# Comparing `tmp/openai_forward-0.1.9.tar.gz` & `tmp/openai_forward-0.2.0.tar.gz`

## Comparing `openai_forward-0.1.9.tar` & `openai_forward-0.2.0.tar`

### file list

```diff
@@ -1,17 +1,17 @@
--rw-r--r--   0        0        0       69 2020-02-02 00:00:00.000000 openai_forward-0.1.9/openai_forward/__init__.py
--rw-r--r--   0        0        0     1586 2020-02-02 00:00:00.000000 openai_forward-0.1.9/openai_forward/__main__.py
--rw-r--r--   0        0        0      802 2020-02-02 00:00:00.000000 openai_forward-0.1.9/openai_forward/app.py
--rw-r--r--   0        0        0     5214 2020-02-02 00:00:00.000000 openai_forward-0.1.9/openai_forward/base.py
--rw-r--r--   0        0        0     4203 2020-02-02 00:00:00.000000 openai_forward-0.1.9/openai_forward/config.py
--rw-r--r--   0        0        0      694 2020-02-02 00:00:00.000000 openai_forward-0.1.9/openai_forward/openai.py
--rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 openai_forward-0.1.9/openai_forward/content/__init__.py
--rw-r--r--   0        0        0     4169 2020-02-02 00:00:00.000000 openai_forward-0.1.9/openai_forward/content/chat.py
--rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 openai_forward-0.1.9/openai_forward/content/image.py
--rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 openai_forward-0.1.9/openai_forward/routers/__init__.py
--rw-r--r--   0        0        0      510 2020-02-02 00:00:00.000000 openai_forward-0.1.9/openai_forward/routers/openai_v1.py
--rw-r--r--   0        0        0     2272 2020-02-02 00:00:00.000000 openai_forward-0.1.9/openai_forward/routers/schemas.py
--rw-r--r--   0        0        0     1907 2020-02-02 00:00:00.000000 openai_forward-0.1.9/.gitignore
--rw-r--r--   0        0        0     1064 2020-02-02 00:00:00.000000 openai_forward-0.1.9/LICENSE
--rw-r--r--   0        0        0     8751 2020-02-02 00:00:00.000000 openai_forward-0.1.9/README.md
--rw-r--r--   0        0        0     1662 2020-02-02 00:00:00.000000 openai_forward-0.1.9/pyproject.toml
--rw-r--r--   0        0        0    10064 2020-02-02 00:00:00.000000 openai_forward-0.1.9/PKG-INFO
+-rw-r--r--   0        0        0       69 2020-02-02 00:00:00.000000 openai_forward-0.2.0/openai_forward/__init__.py
+-rw-r--r--   0        0        0     1641 2020-02-02 00:00:00.000000 openai_forward-0.2.0/openai_forward/__main__.py
+-rw-r--r--   0        0        0      422 2020-02-02 00:00:00.000000 openai_forward-0.2.0/openai_forward/app.py
+-rw-r--r--   0        0        0     5594 2020-02-02 00:00:00.000000 openai_forward-0.2.0/openai_forward/base.py
+-rw-r--r--   0        0        0     4438 2020-02-02 00:00:00.000000 openai_forward-0.2.0/openai_forward/config.py
+-rw-r--r--   0        0        0      654 2020-02-02 00:00:00.000000 openai_forward-0.2.0/openai_forward/openai.py
+-rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 openai_forward-0.2.0/openai_forward/content/__init__.py
+-rw-r--r--   0        0        0     4304 2020-02-02 00:00:00.000000 openai_forward-0.2.0/openai_forward/content/chat.py
+-rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 openai_forward-0.2.0/openai_forward/content/image.py
+-rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 openai_forward-0.2.0/openai_forward/routers/__init__.py
+-rw-r--r--   0        0        0      512 2020-02-02 00:00:00.000000 openai_forward-0.2.0/openai_forward/routers/openai_v1.py
+-rw-r--r--   0        0        0     2330 2020-02-02 00:00:00.000000 openai_forward-0.2.0/openai_forward/routers/schemas.py
+-rw-r--r--   0        0        0     1994 2020-02-02 00:00:00.000000 openai_forward-0.2.0/.gitignore
+-rw-r--r--   0        0        0     1064 2020-02-02 00:00:00.000000 openai_forward-0.2.0/LICENSE
+-rw-r--r--   0        0        0     8074 2020-02-02 00:00:00.000000 openai_forward-0.2.0/README.md
+-rw-r--r--   0        0        0     1686 2020-02-02 00:00:00.000000 openai_forward-0.2.0/pyproject.toml
+-rw-r--r--   0        0        0     9408 2020-02-02 00:00:00.000000 openai_forward-0.2.0/PKG-INFO
```

### Comparing `openai_forward-0.1.9/openai_forward/__main__.py` & `openai_forward-0.2.0/openai_forward/__main__.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,25 +1,27 @@
+import os
+
 import fire
 import uvicorn
-import os
 
 
 class Cli:
     @staticmethod
-    def run(port=8000,
-            workers=1,
-            api_key=None,
-            forward_key=None,
-            base_url=None,
-            log_chat=None,
-            route_prefix=None,
-            ip_whitelist=None,
-            ip_blacklist=None,
-            ):
-        """ Run forwarding serve.
+    def run(
+        port=8000,
+        workers=1,
+        api_key=None,
+        forward_key=None,
+        base_url=None,
+        log_chat=None,
+        route_prefix=None,
+        ip_whitelist=None,
+        ip_blacklist=None,
+    ):
+        """Run forwarding serve.
 
         Parameters
         ----------
 
         port: int, default 8000
         workers: int, 1
         api_key: str, None
@@ -41,22 +43,24 @@
         if route_prefix:
             os.environ['ROUTE_PREFIX'] = route_prefix
         if ip_whitelist:
             os.environ['IP_WHITELIST'] = ip_whitelist
         if ip_blacklist:
             os.environ['IP_BLACKLIST'] = ip_blacklist
 
+        ssl_keyfile = os.environ.get("ssl_keyfile", None) or None
+        ssl_certfile = os.environ.get("ssl_certfile", None) or None
         uvicorn.run(
             app="openai_forward.app:app",
             host="0.0.0.0",
             port=port,
             workers=workers,
             app_dir='..',
-            ssl_keyfile=os.environ.get("ssl_keyfile", None),
-            ssl_certfile=os.environ.get("ssl_certfile", None),
+            ssl_keyfile=ssl_keyfile,
+            ssl_certfile=ssl_certfile,
         )
 
 
 def main():
     fire.Fire(Cli)
```

### Comparing `openai_forward-0.1.9/openai_forward/base.py` & `openai_forward-0.2.0/openai_forward/base.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,16 +1,18 @@
-from fastapi import Request, HTTPException, status
+import os
+from itertools import cycle
+
+import httpx
+from fastapi import HTTPException, Request, status
 from fastapi.responses import StreamingResponse
 from loguru import logger
-import httpx
 from starlette.background import BackgroundTask
-import os
-from itertools import cycle
+
+from .config import env2list, print_startup_info, setting_log
 from .content.chat import ChatSaver
-from .config import env2list, print_startup_info
 
 
 class OpenaiBase:
     BASE_URL = os.environ.get("OPENAI_BASE_URL", "https://api.openai.com").strip()
     ROUTE_PREFIX = os.environ.get("ROUTE_PREFIX", "").strip()
     _LOG_CHAT = os.environ.get("LOG_CHAT", "False").strip().lower() == "true"
     _openai_api_key_list = env2list("OPENAI_API_KEY", sep=" ")
@@ -22,24 +24,33 @@
 
     if ROUTE_PREFIX:
         if ROUTE_PREFIX.endswith('/'):
             ROUTE_PREFIX = ROUTE_PREFIX[:-1]
         if not ROUTE_PREFIX.startswith('/'):
             ROUTE_PREFIX = '/' + ROUTE_PREFIX
     timeout = 30
-    chatsaver = ChatSaver(save_interval=10)
-    print_startup_info(BASE_URL, ROUTE_PREFIX, _openai_api_key_list, _FWD_KEYS, _LOG_CHAT)
+
+    print_startup_info(
+        BASE_URL, ROUTE_PREFIX, _openai_api_key_list, _FWD_KEYS, _LOG_CHAT
+    )
+    if _LOG_CHAT:
+        setting_log(save_file=False)
+        chatsaver = ChatSaver(save_interval=10)
 
     def validate_request_host(self, ip):
         if self.IP_WHITELIST and ip not in self.IP_WHITELIST:
-            raise HTTPException(status_code=status.HTTP_403_FORBIDDEN,
-                                detail=f"Forbidden, ip={ip} not in whitelist!")
+            raise HTTPException(
+                status_code=status.HTTP_403_FORBIDDEN,
+                detail=f"Forbidden, ip={ip} not in whitelist!",
+            )
         if self.IP_BLACKLIST and ip in self.IP_BLACKLIST:
-            raise HTTPException(status_code=status.HTTP_403_FORBIDDEN,
-                                detail=f"Forbidden, ip={ip} in blacklist!")
+            raise HTTPException(
+                status_code=status.HTTP_403_FORBIDDEN,
+                detail=f"Forbidden, ip={ip} in blacklist!",
+            )
 
     @classmethod
     async def aiter_bytes(cls, r: httpx.Response, route_path: str):
         bytes_ = b''
         async for chunk in r.aiter_bytes():
             bytes_ += chunk
             yield chunk
@@ -47,67 +58,84 @@
             target_info = cls.chatsaver.parse_bytes_to_content(bytes_, route_path)
             cls.chatsaver.add_chat({target_info['role']: target_info['content']})
         except Exception as e:
             logger.debug(f"log chat (not) error:\n{e=}")
 
     @classmethod
     async def _reverse_proxy(cls, request: Request):
-        client: httpx.AsyncClient = request.app.state.client
+        client = httpx.AsyncClient(base_url=cls.BASE_URL, http1=True, http2=False)
         url_path = request.url.path
-        url_path = url_path[len(cls.ROUTE_PREFIX):]
+        url_path = url_path[len(cls.ROUTE_PREFIX) :]
         url = httpx.URL(path=url_path, query=request.url.query.encode('utf-8'))
         headers = dict(request.headers)
         auth = headers.pop("authorization", None)
         if auth and str(auth).startswith("Bearer sk-"):
             tmp_headers = {'Authorization': auth}
         elif cls._openai_api_key_list:
             logger.info(f"Use forward key: {cls._use_forward_key}")
             if cls._use_forward_key:
                 fk_prefix = "Bearer fk-"
                 logger.info(f"current forward key: {auth}")
-                if auth and str(auth).startswith(fk_prefix) and auth[len("Bearer "):] in cls._FWD_KEYS:
+                if (
+                    auth
+                    and str(auth).startswith(fk_prefix)
+                    and auth[len("Bearer ") :] in cls._FWD_KEYS
+                ):
                     auth = "Bearer " + next(cls._cycle_api_key)
                     tmp_headers = {'Authorization': auth}
                 else:
                     tmp_headers = {}
             else:
                 auth = "Bearer " + next(cls._cycle_api_key)
                 tmp_headers = {'Authorization': auth}
         else:
             tmp_headers = {}
 
         log_chat_completions = False
         if cls._LOG_CHAT and request.method == 'POST':
             try:
-                chat_info = await cls.chatsaver.parse_payload_to_content(request, route_path=url_path)
+                chat_info = await cls.chatsaver.parse_payload_to_content(
+                    request, route_path=url_path
+                )
                 if chat_info:
                     cls.chatsaver.add_chat(chat_info)
                     log_chat_completions = True
             except Exception as e:
-                logger.debug(f"log chat error:\n{request.client.host=} {request.method=}: {e}")
+                logger.debug(
+                    f"log chat error:\n{request.client.host=} {request.method=}: {e}"
+                )
 
         tmp_headers.update({"Content-Type": "application/json"})
         req = client.build_request(
-            request.method, url, headers=tmp_headers,
+            request.method,
+            url,
+            headers=tmp_headers,
             content=request.stream(),
             timeout=cls.timeout,
         )
         try:
             r = await client.send(req, stream=True)
         except (httpx.ConnectError, httpx.ConnectTimeout) as e:
-            error_info = f"{type(e)}: {e} | " \
-                         f"Please check if host={request.client.host} can access [{cls.BASE_URL}] successfully?"
+            error_info = (
+                f"{type(e)}: {e} | "
+                f"Please check if host={request.client.host} can access [{cls.BASE_URL}] successfully?"
+            )
             logger.error(error_info)
-            raise HTTPException(status_code=status.HTTP_504_GATEWAY_TIMEOUT, detail=error_info)
+            raise HTTPException(
+                status_code=status.HTTP_504_GATEWAY_TIMEOUT, detail=error_info
+            )
         except Exception as e:
             error_info = f"{type(e)}: {e}"
             logger.error(error_info)
-            raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=error_info)
+            raise HTTPException(
+                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=error_info
+            )
 
-        aiter_bytes = cls.aiter_bytes(r, url_path) if log_chat_completions else r.aiter_bytes()
+        aiter_bytes = (
+            cls.aiter_bytes(r, url_path) if log_chat_completions else r.aiter_bytes()
+        )
         return StreamingResponse(
             aiter_bytes,
             status_code=r.status_code,
-            # headers=r.headers, # do not use r.headers, it will cause error
             media_type=r.headers.get("content-type"),
-            background=BackgroundTask(r.aclose)
+            background=BackgroundTask(r.aclose),
         )
```

### Comparing `openai_forward-0.1.9/openai_forward/config.py` & `openai_forward-0.2.0/openai_forward/config.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,37 +1,46 @@
-from loguru import logger
-import orjson
-from sparrow import relp
-from typing import Union, List, Dict
-import sys
 import logging
 import os
+import sys
 import time
+from typing import Dict, List, Union
+
+import orjson
+from loguru import logger
 from rich import print
 from rich.panel import Panel
 from rich.table import Table
+from sparrow import relp
 
 
 def print_startup_info(base_url, route_prefix, api_key, forward_key, log_chat):
     try:
         from dotenv import load_dotenv
+
         load_dotenv('.env')
     except Exception:
         ...
     route_prefix = route_prefix or "/"
     api_key_info = True if len(api_key) else False
     forward_key_info = True if len(forward_key) else False
     table = Table(title="", box=None, width=100)
     table.add_column("base-url", justify="left", style="#df412f")
     table.add_column("route-prefix", justify="center", style="#df412f")
     table.add_column("openai-api-key", justify="center", style="green")
     table.add_column("forward-key", justify="center", style="green")
     table.add_column("Log-chat", justify="center", style="green")
     table.add_column("Log-dir", justify="center", style="#f5bb00")
-    table.add_row(base_url, route_prefix, str(api_key_info), str(forward_key_info), str(log_chat), "./Log/*.log")
+    table.add_row(
+        base_url,
+        route_prefix,
+        str(api_key_info),
+        str(forward_key_info),
+        str(log_chat),
+        "./Log/*.log",
+    )
     print(Panel(table, title="ğŸ¤—openai-forward is ready to serve!", expand=False))
 
 
 class InterceptHandler(logging.Handler):
     def emit(self, record):
         # Get corresponding Loguru level if it exists
         try:
@@ -40,34 +49,43 @@
             level = record.levelno
 
         # Find caller from where originated the logged message
         frame, depth = logging.currentframe(), 6
         while frame.f_code.co_filename == logging.__file__:
             frame = frame.f_back
             depth += 1
-        logger.opt(depth=depth, exception=record.exc_info).log(level, record.getMessage())
+        logger.opt(depth=depth, exception=record.exc_info).log(
+            level, record.getMessage()
+        )
 
 
-def setting_log(log_name, multi_process=True):
+def setting_log(save_file=False, log_name=None, multi_process=True):
     # TODO ä¿®å¤æ—¶åŒºé…ç½®
     if os.environ.get("TZ") == "Asia/Shanghai":
         os.environ['TZ'] = "UTC-8"
         if hasattr(time, 'tzset'):
             time.tzset()
 
     logging.root.handlers = [InterceptHandler()]
     for name in logging.root.manager.loggerDict.keys():
         logging.getLogger(name).handlers = []
         logging.getLogger(name).propagate = True
-    logger_config = {
-        "handlers": [
-            {"sink": sys.stdout, "level": "DEBUG"},
-            {"sink": f"./Log/{log_name}.log", "enqueue": multi_process, "rotation": "100 MB", "level": "INFO"},
-        ],
-    }
+
+    config_handlers = [
+        {"sink": sys.stdout, "level": "DEBUG"},
+    ]
+    if save_file:
+        config_handlers += {
+            "sink": f"./Log/{log_name}.log",
+            "enqueue": multi_process,
+            "rotation": "100 MB",
+            "level": "INFO",
+        }
+
+    logger_config = {"handlers": config_handlers}
     logger.configure(**logger_config)
 
 
 def yaml_dump(data, filepath, rel_path=False, mode='w'):
     abs_path = relp(filepath, parents=1) if rel_path else filepath
     from yaml import dump
 
@@ -95,15 +113,17 @@
 
 def json_load(filepath: str, rel=False, mode='rb'):
     abs_path = relp(filepath, parents=1) if rel else filepath
     with open(abs_path, mode=mode) as f:
         return orjson.loads(f.read())
 
 
-def json_dump(data: Union[List, Dict], filepath: str, rel=False, indent_2=False, mode='wb'):
+def json_dump(
+    data: Union[List, Dict], filepath: str, rel=False, indent_2=False, mode='wb'
+):
     orjson_option = 0
     if indent_2:
         orjson_option = orjson.OPT_INDENT_2
     abs_path = relp(filepath, parents=1) if rel else filepath
     with open(abs_path, mode=mode) as f:
         f.write(orjson.dumps(data, option=orjson_option))
```

### Comparing `openai_forward-0.1.9/openai_forward/content/chat.py` & `openai_forward-0.2.0/openai_forward/content/chat.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,16 +1,17 @@
+import os
+from pathlib import Path
+from typing import Dict, List
+
 import orjson
-from orjson import JSONDecodeError
-from loguru import logger
-from httpx._decoders import LineDecoder
 from fastapi import Request
-from pathlib import Path
+from httpx._decoders import LineDecoder
+from loguru import logger
+from orjson import JSONDecodeError
 from sparrow import relp
-from typing import List, Dict
-import os
 
 decoder = LineDecoder()
 
 
 def _parse_iter_line_content(line: str):
     line = line[6:]
     try:
@@ -60,14 +61,17 @@
         self._init_chat_file()
 
     @property
     def chat_file(self):
         return os.path.join(self._log_dir, f"chat_{self._file_idx}.txt")
 
     def _init_chat_file(self):
+        _log_dir = Path(self._log_dir)
+        if not _log_dir.exists():
+            _log_dir.mkdir(parents=True)
         while Path(self.chat_file).exists():
             self._file_idx += 1
 
     @staticmethod
     async def parse_payload_to_content(request: Request, route_path: str):
         payload = await request.json()
         if route_path == "/v1/chat/completions":
@@ -101,15 +105,17 @@
                 logger.info(f"{self._cur_chat_file_size} is too large, create new file")
                 self._file_idx += 1
                 self._cur_chat_file_size = 1
             self.dump_chat_list(self._chat_list, self.chat_file, mode='a+', _end='\n')
             self._chat_list = []
 
     @staticmethod
-    def dump_chat_list(data: List[Dict], filepath: str, rel=False, mode='w', _sep='\n', _end="\n"):
+    def dump_chat_list(
+        data: List[Dict], filepath: str, rel=False, mode='w', _sep='\n', _end="\n"
+    ):
         str_data = _sep.join([str(i) for i in data]) + _end
         abs_path = relp(filepath, parents=1) if rel else filepath
         with open(abs_path, mode=mode) as f:
             f.write(str_data)
 
     @staticmethod
     def load_chat_list(filepath: str, rel=False, mode='r', _sep='\n'):
```

### Comparing `openai_forward-0.1.9/openai_forward/routers/schemas.py` & `openai_forward-0.2.0/openai_forward/routers/schemas.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,31 +1,54 @@
 from __future__ import annotations
 
+from typing import Dict, List, Optional, Union
+
 from pydantic import BaseModel, Field
-from typing import List, Dict, Optional, Union
 
 
 class OpenAIV1ChatCompletion(BaseModel):
     """Creates a completion for the chat message"""
-    model: str = Field(..., description="The model to use for the completion", example="gpt-3.5-turbo")
-    messages: List[Dict[str, str]] = Field(..., description="The message to complete",
-                                           example=[{"role": "user", "content": "hi"}])
+
+    model: str = Field(
+        ..., description="The model to use for the completion", example="gpt-3.5-turbo"
+    )
+    messages: List[Dict[str, str]] = Field(
+        ...,
+        description="The message to complete",
+        example=[{"role": "user", "content": "hi"}],
+    )
     temperature: float = Field(default=1, description="0ä¼šå¯¼è‡´æ›´ç¡®å®šçš„ç»“æœï¼Œ1ä¼šå¯¼è‡´æ›´éšæœºçš„ç»“æœ")
     top_p: float = Field(default=1, description="0ä¼šå¯¼è‡´æ›´ç¡®å®šçš„ç»“æœï¼Œ1ä¼šå¯¼è‡´æ›´éšæœºçš„ç»“æœ")
-    n: int = Field(default=1, description="How many chat completion choices to generate for each input message.")
+    n: int = Field(
+        default=1,
+        description="How many chat completion choices to generate for each input message.",
+    )
     stream: bool = Field(default=False)
-    stop: Union[List[str], str, None] = Field(default=None,
-                                              description="Up to 4 sequences where the API will stop generating further tokens.")
-    max_tokens: Union[int, None] = Field(default=None, description="The maximum number of tokens to generate in the chat completion. The total length of input tokens and generated tokens is limited by the model's context length.")
-    presence_penalty: float = Field(default=0, description="Number between -2.0 and 2.0. ")
-    frequency_penalty: float = Field(default=0, description="Number between -2.0 and 2.0. ")
-    logit_bias: Optional[Dict[str, float]] = Field(default=None, description="å–å€¼[-100, 100]ï¼Œ å–å€¼è¶Šå¤§ï¼Œç”Ÿæˆçš„ç»“æœè¶Šåå‘äºè¯¥tokenã€‚ å–-100è¡¨ç¤ºå®Œå…¨ä¸è€ƒè™‘è¯¥tokenã€‚")
-    user: Optional[str] = Field(default=None,
-                                description="A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. ",
-                                )
+    stop: Union[List[str], str, None] = Field(
+        default=None,
+        description="Up to 4 sequences where the API will stop generating further tokens.",
+    )
+    max_tokens: Union[int, None] = Field(
+        default=None,
+        description="The maximum number of tokens to generate in the chat completion. The total length of input tokens and generated tokens is limited by the model's context length.",
+    )
+    presence_penalty: float = Field(
+        default=0, description="Number between -2.0 and 2.0. "
+    )
+    frequency_penalty: float = Field(
+        default=0, description="Number between -2.0 and 2.0. "
+    )
+    logit_bias: Optional[Dict[str, float]] = Field(
+        default=None,
+        description="å–å€¼[-100, 100]ï¼Œ å–å€¼è¶Šå¤§ï¼Œç”Ÿæˆçš„ç»“æœè¶Šåå‘äºè¯¥tokenã€‚ å–-100è¡¨ç¤ºå®Œå…¨ä¸è€ƒè™‘è¯¥tokenã€‚",
+    )
+    user: Optional[str] = Field(
+        default=None,
+        description="A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. ",
+    )
 
     class Config:
         schema_extra = {
             "example": {
                 "model": "gpt-3.5-turbo",
                 "messages": [{"role": "user", "content": "hi"}],
                 "stream": False,
```

### Comparing `openai_forward-0.1.9/.gitignore` & `openai_forward-0.2.0/.gitignore`

 * *Files 13% similar despite different names*

```diff
@@ -1,17 +1,21 @@
+.github/release-template.ejs
+scripts/release.sh
+node_modules
+package-lock.json
+package.json
 .idea/
 .vscode/
 .DS_Store
 third-party/
 run.sh
 ssl/
 chat.yaml
 chat_*.yaml
 
-.env.example
 Log/
 Log-caloi-top/
 dist/
 # Byte-compiled / optimized / DLL files
 __pycache__/
 *.py[cod]
 *$py.class
@@ -135,7 +139,8 @@
 # mypy
 .mypy_cache/
 .dmypy.json
 dmypy.json
 
 # Pyre type checker
 .pyre/
+.vercel
```

### Comparing `openai_forward-0.1.9/LICENSE` & `openai_forward-0.2.0/LICENSE`

 * *Files identical despite different names*

### Comparing `openai_forward-0.1.9/README.md` & `openai_forward-0.2.0/PKG-INFO`

 * *Files 10% similar despite different names*

```diff
@@ -1,7 +1,41 @@
+Metadata-Version: 2.1
+Name: openai_forward
+Version: 0.2.0
+Summary: ğŸš€ Openai api forward Â· OpenAI æ¥å£è½¬å‘æœåŠ¡ Â· stream forwarding
+Project-URL: Homepage, https://github.com/beidongjiedeguang/openai-forward
+Project-URL: Documentation, https://github.com/beidongjiedeguang/openai-forward#openai-forward
+Project-URL: Issues, https://github.com/beidongjiedeguang/openai-forward/issues
+Project-URL: Source, https://github.com/beidongjiedeguang/openai-forward
+Author-email: kunyuan <beidongjiedeguang@gmail.com>
+License-Expression: MIT
+License-File: LICENSE
+Keywords: OpenAI API Forwarding,chatgpt,fastapi,httpx,openai,openai-api,openai-proxy,python,streaming-api
+Classifier: Development Status :: 5 - Production/Stable
+Classifier: Operating System :: OS Independent
+Classifier: Programming Language :: Python :: 3
+Requires-Python: >=3.6
+Requires-Dist: fastapi
+Requires-Dist: httpx
+Requires-Dist: loguru
+Requires-Dist: orjson
+Requires-Dist: python-dotenv
+Requires-Dist: pytz
+Requires-Dist: sparrow-python>=0.1.3
+Requires-Dist: uvicorn
+Provides-Extra: bard
+Requires-Dist: googlebard; extra == 'bard'
+Provides-Extra: chatgpt
+Requires-Dist: revchatgpt; extra == 'chatgpt'
+Provides-Extra: edge
+Requires-Dist: edgegpt; extra == 'edge'
+Provides-Extra: ssl
+Requires-Dist: certbot; extra == 'ssl'
+Description-Content-Type: text/markdown
+
 **ä¸­æ–‡** | [**English**](./README_EN.md)
 
 <h1 align="center">
     <br>
     OpenAI Forward
     <br>
 </h1>
@@ -20,267 +54,216 @@
     </a>
     <a href="https://github.com/beidongjiedeguang/openai-forward">
         <img alt="GitHub repo size" src="https://img.shields.io/github/repo-size/beidongjiedeguang/openai-forward">
     </a>
     <a href="https://hub.docker.com/r/beidongjiedeguang/openai-forward">
         <img alt="docer image size" src="https://img.shields.io/docker/image-size/beidongjiedeguang/openai-forward?style=flat&label=docker image">
     </a>
-    <a href="https://github.com/beidongjiedeguang/openai-forward/actions/workflows/run_tests.yaml">
-        <img alt="tests" src="https://img.shields.io/github/actions/workflow/status/beidongjiedeguang/openai-forward/run_tests.yml?label=tests">
+    <a href="https://github.com/beidongjiedeguang/openai-forward/actions/workflows/ci.yml">
+        <img alt="tests" src="https://img.shields.io/github/actions/workflow/status/beidongjiedeguang/openai-forward/ci.yml?label=tests">
     </a>
-    <a href="https://pypi.org/project/openai_forward/">
+    <a href="https://pypistats.org/packages/openai-forward">
         <img alt="pypi downloads" src="https://img.shields.io/pypi/dm/openai_forward">
     </a>
     <a href="https://codecov.io/gh/beidongjiedeguang/openai-forward">
         <img alt="codecov" src="https://codecov.io/gh/beidongjiedeguang/openai-forward/branch/dev/graph/badge.svg">
     </a>
 </p>
 
 
 
 æœ¬é¡¹ç›®ç”¨äºè§£å†³ä¸€äº›åœ°åŒºæ— æ³•ç›´æ¥è®¿é—®OpenAIçš„é—®é¢˜ï¼Œå°†è¯¥æœåŠ¡éƒ¨ç½²åœ¨å¯ä»¥æ­£å¸¸è®¿é—®openai
 apiçš„æœåŠ¡å™¨ä¸Šï¼Œé€šè¿‡è¯¥æœåŠ¡è½¬å‘OpenAIçš„è¯·æ±‚ã€‚å³æ­å»ºåå‘ä»£ç†æœåŠ¡  
 
 ---
 
-æµ‹è¯•è®¿é—®ï¼šhttps://caloi.top/openai/v1/chat/completions  
-æˆ–è€…è¯´ https://caloi.top/openai ç­‰ä»·äº https://api.openai.com
+ç”±æœ¬é¡¹ç›®æ­å»ºçš„é•¿æœŸä»£ç†åœ°å€ï¼š
+> https://api.openai-forward.top  
+
 
----
 
-# ç›®å½•
+## ç›®å½•
 
 - [åŠŸèƒ½](#åŠŸèƒ½)
+- [éƒ¨ç½²æŒ‡å—](#éƒ¨ç½²æŒ‡å—)
 - [åº”ç”¨](#åº”ç”¨)
-- [å®‰è£…éƒ¨ç½²](#å®‰è£…éƒ¨ç½²)
-- [æœåŠ¡è°ƒç”¨](#æœåŠ¡è°ƒç”¨)
 - [é…ç½®é€‰é¡¹](#é…ç½®é€‰é¡¹)
 - [èŠå¤©æ—¥å¿—](#èŠå¤©æ—¥å¿—)
 - [é«˜çº§é…ç½®](#é«˜çº§é…ç½®)
 
-# åŠŸèƒ½
+## åŠŸèƒ½
 **åŸºç¡€åŠŸèƒ½**  
 - [x] æ”¯æŒè½¬å‘OpenAIæ‰€æœ‰æ¥å£
 - [x] æ”¯æŒæµå¼å“åº”
 - [x] æ”¯æŒæŒ‡å®šè½¬å‘è·¯ç”±å‰ç¼€
 - [x] dockeréƒ¨ç½²
 - [x] pip å®‰è£…éƒ¨ç½²
+- [x] vercel ä¸€é”®ä¸ªäººå…è´¹éƒ¨ç½²
+  [![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https%3A%2F%2Fgithub.com%2Fbeidongjiedeguang%2Fopenai-forward&project-name=openai-forward&repository-name=openai-forward&framework=other)
 
 **é«˜çº§åŠŸèƒ½**  
 - [x] å®æ—¶è®°å½•èŠå¤©è®°å½•(åŒ…æ‹¬æµå¼å“åº”çš„èŠå¤©å†…å®¹)
-- [x] æ”¯æŒé»˜è®¤openai api key(å¤šapi key å¾ªç¯è°ƒç”¨)
-- [x] è‡ªå®šä¹‰forward api key ä»£æ›¿ openai api key (è§é«˜çº§é…ç½®)
+- [x] å…è®¸è¾“å…¥å¤šä¸ªopenai api key ç»„æˆè½®è¯¢æ± 
+- [x] è‡ªå®šä¹‰ api key (è§é«˜çº§é…ç½®)
 - [x] æ”¯æŒè¯·æ±‚IPéªŒè¯(IPç™½åå•ä¸é»‘åå•)
 
-# åº”ç”¨
+## éƒ¨ç½²æŒ‡å—
 
-> è¿™é‡Œä»¥ä¸ªäººä½¿ç”¨è¯¥é¡¹ç›®æ­å»ºå¥½çš„ä»£ç†æœåŠ¡ https://caloi.top/openai ä¸ºä¾‹
+æä¾›ä¸‰ç§éƒ¨ç½²æ–¹å¼
+1. [vps + pip å®‰è£…éƒ¨ç½²](deploy.md#pip-æ¨è) (æ¨è)
+2. [vps + Docker](deploy.md#docker-æ¨è) (æ¨è) 
+    > https://api.openai-forward.top 
+3. [ä¸€é”®Verceléƒ¨ç½²](deploy.md#vercel-ä¸€é”®éƒ¨ç½²) 
+   > https://vercel.openai-forward.top 
 
-### [caloi.top](https://caloi.top)
+## åº”ç”¨
+
+### [èŠå¤©åº”ç”¨](https://chat.beidongjiedeguang.top)
 
 åŸºäºå¼€æºé¡¹ç›®[ChatGPT-Next-Web](https://github.com/Yidadaa/ChatGPT-Next-Web)æ­å»ºè‡ªå·±çš„chatgptæœåŠ¡  
 æ›¿æ¢dockerå¯åŠ¨å‘½ä»¤ä¸­çš„ `BASE_URL`ä¸ºæˆ‘ä»¬è‡ªå·±æ­å»ºçš„ä»£ç†æœåŠ¡åœ°å€
 
 ```bash 
 docker run -d \
     -p 3000:3000 \
     -e OPENAI_API_KEY="sk-******" \
-    -e BASE_URL="caloi.top/openai" \
-    -e CODE="<your password>" \
+    -e BASE_URL="https://api.openai-forward.top" \
+    -e CODE="kunyuan" \
     yidadaa/chatgpt-next-web 
 ``` 
+è¿™é‡Œéƒ¨ç½²äº†ä¸€ä¸ªï¼Œä¾›å¤§å®¶è½»åº¦ä½¿ç”¨:  
+ https://chat.beidongjiedeguang.top , è®¿é—®å¯†ç : `kunyuan` 
 
-è®¿é—® https://caloi.top ã€‚è®¿é—®å¯†ç ä¸º `beidongjiedeguang`
-
-### åœ¨æ¨¡å—ä¸­ä½¿ç”¨
+### åœ¨ä»£ç ä¸­ä½¿ç”¨
 
 **JS/TS**
 
 ```diff
   import { Configuration } from "openai";
   
   const configuration = new Configuration({
-+ basePath: "https://caloi.top/openai/v1",
++ basePath: "https://api.openai-forward.top/v1",
   apiKey: "sk-******",
   });
 ```
 
 **Python**
 
 ```diff
   import openai
-+ openai.api_base = "https://caloi.top/openai/v1"
++ openai.api_base = "https://api.openai-forward.top/v1"
   openai.api_key = "sk-******"
 ```
 
-### Image Generation (DALL-E):
+**gpt-3.5-turbo**
+```bash
+curl https://api.openai-forward.top/v1/chat/completions \
+  -H "Content-Type: application/json" \
+  -H "Authorization: Bearer sk-******" \
+  -d '{
+    "model": "gpt-3.5-turbo",
+    "messages": [{"role": "user", "content": "Hello!"}]
+  }'
+```
 
+**Image Generation (DALL-E)**
 ```bash
-curl --location 'https://caloi.top/openai/v1/images/generations' \
+curl --location 'https://api.openai-forward.top/v1/images/generations' \
 --header 'Authorization: Bearer sk-******' \
 --header 'Content-Type: application/json' \
 --data '{
     "prompt": "A photo of a cat",
     "n": 1,
     "size": "512x512"
 }'
 ```
 
-# å®‰è£…éƒ¨ç½²
-
-é€‰æ‹©ä¸€ç§å³å¯
 
-## pip
-
-**å®‰è£…**
-
-```bash
-pip install openai-forward
-```
-
-**è¿è¡Œè½¬å‘æœåŠ¡**  
-å¯é€šè¿‡`--port`æŒ‡å®šç«¯å£å·ï¼Œé»˜è®¤ä¸º`8000`
-
-```bash
-openai_forward run --port=9999 
-```
-
-æœåŠ¡å°±æ­å»ºå®Œæˆäº†ï¼Œä½¿ç”¨æ–¹å¼åªéœ€å°†`https://api.openai.com` æ›¿æ¢ä¸ºæœåŠ¡æ‰€åœ¨ç«¯å£`http://{ip}:{port}` å³å¯ã€‚
-
-å½“ç„¶ä¹Ÿå¯ä»¥å°† OPENAI_API_KEY ä½œä¸ºç¯å¢ƒå˜é‡æˆ–`--api_key`å‚æ•°ä¼ å…¥ä½œä¸ºé»˜è®¤api keyï¼Œ è¿™æ ·å®¢æˆ·ç«¯åœ¨è¯·æ±‚ç›¸å…³è·¯ç”±æ—¶å¯ä»¥æ— éœ€åœ¨Headerä¸­ä¼ å…¥Authorizationã€‚
-å¸¦é»˜è®¤api keyçš„å¯åŠ¨æ–¹å¼ï¼š
-
-```bash
-openai_forward run --port=9999 --api_key="sk-******"
-```
-
-æ³¨: å¦‚æœæ—¢å­˜åœ¨é»˜è®¤api keyåˆåœ¨è¯·æ±‚å¤´ä¸­ä¼ å…¥äº†api keyï¼Œåˆ™ä»¥è¯·æ±‚å¤´ä¸­çš„api keyä¼šè¦†ç›–é»˜è®¤api key.
-
-## Docker (æ¨è)
-
-```bash
-docker run -d -p 9999:8000 beidongjiedeguang/openai-forward:latest 
-```
-
-å°†æ˜ å°„å®¿ä¸»æœºçš„9999ç«¯å£ï¼Œé€šè¿‡`http://{ip}:9999`è®¿é—®æœåŠ¡ã€‚  
-æ³¨ï¼šåŒæ ·å¯ä»¥åœ¨å¯åŠ¨å‘½ä»¤ä¸­é€šè¿‡-eä¼ å…¥ç¯å¢ƒå˜é‡OPENAI_API_KEY=sk-xxxä½œä¸ºé»˜è®¤api key
-
-## æºç éƒ¨ç½²
-
-```bash
-git clone https://github.com/beidongjiedeguang/openai-forward.git --depth=1
-cd openai-forward
-```
-
-**Docker**
-
-```bash
-docker-compose up
-```
-
-**pip**
-
-```bash
-pip install -e .
-openai-forward run 
-```
-
-# æœåŠ¡è°ƒç”¨
-
-æ›¿æ¢openaiçš„apiåœ°å€ä¸ºè¯¥æœåŠ¡çš„åœ°å€å³å¯ï¼Œå¦‚ï¼š
-
-```bash
-https://api.openai.com/v1/chat/completions
-```
-
-æ›¿æ¢ä¸º
-
-```bash
-http://{ip}:{port}/v1/chat/completions
-```
-
-# é…ç½®é€‰é¡¹
+## é…ç½®é€‰é¡¹
 
 **`openai-forward run`å‚æ•°é…ç½®é¡¹**
 
 | é…ç½®é¡¹       | è¯´æ˜ | é»˜è®¤å€¼ |
 |-----------| --- | :---: |
 | --port    | æœåŠ¡ç«¯å£å· | 8000 |
 | --workers | å·¥ä½œè¿›ç¨‹æ•° | 1 |
 
+æ›´å¤šå‚æ•° `openai-forward run --help` æŸ¥çœ‹
+
 **ç¯å¢ƒå˜é‡é…ç½®é¡¹**  
 æ”¯æŒä»è¿è¡Œç›®å½•ä¸‹çš„`.env`æ–‡ä»¶ä¸­è¯»å–: 
 
 | ç¯å¢ƒå˜é‡            | è¯´æ˜                                                              |           é»˜è®¤å€¼            |
 |-----------------|-----------------------------------------------------------------|:------------------------:|
 | OPENAI_API_KEY  | é»˜è®¤openai api keyï¼Œæ”¯æŒå¤šä¸ªé»˜è®¤api key, ä»¥ `sk-` å¼€å¤´ï¼Œ ä»¥ç©ºæ ¼åˆ†å‰²      |            æ—              |
 | FORWARD_KEY     | å…è®¸è°ƒç”¨æ–¹ä½¿ç”¨è¯¥keyä»£æ›¿openai api keyï¼Œæ”¯æŒå¤šä¸ªforward key, ä»¥`fk-` å¼€å¤´, ä»¥ç©ºæ ¼åˆ†å‰² |      æ—              |
 | OPENAI_BASE_URL | è½¬å‘base url                                                      | `https://api.openai.com` |
 | LOG_CHAT        | æ˜¯å¦è®°å½•èŠå¤©å†…å®¹                                                        |          `true`          |
 | ROUTE_PREFIX    | è·¯ç”±å‰ç¼€                                                            |            æ—              |
 | IP_WHITELIST    | ipç™½åå•, ç©ºæ ¼åˆ†å¼€                                                     |           æ—             |
 | IP_BLACKLIST    | ipé»‘åå•, ç©ºæ ¼åˆ†å¼€                                                     |           æ—             | 
 
-# èŠå¤©æ—¥å¿—
-
-ä¿å­˜è·¯å¾„åœ¨å½“å‰ç›®å½•ä¸‹çš„`Log/`è·¯å¾„ä¸­ã€‚  
-èŠå¤©æ—¥å¿—ä»¥ `chat_`å¼€å¤´, é»˜è®¤æ¯5è½®å¯¹è¯å†™å…¥ä¸€æ¬¡æ–‡ä»¶    
-è®°å½•æ ¼å¼ä¸º
-
-```text
-{'host': xxx, 'model': xxx, 'message': [{'user': xxx}, {'assistant': xxx}]}
-{'assistant': xxx}
-
-{'host': ...}
-{'assistant': ...}
-
-...
-```
 
-# é«˜çº§é…ç½®
+## é«˜çº§é…ç½®
 
 **è®¾ç½®api_keyä¸ºè‡ªå·±è®¾ç½®çš„forward key**  
 éœ€è¦é…ç½® OPENAI_API_KEY å’Œ FORWARD_KEY, ä¾‹å¦‚
 
 ```bash
 OPENAI_API_KEY=sk-*******
 FORWARD_KEY=fk-****** # è¿™é‡Œfk-tokenç”±æˆ‘ä»¬è‡ªå·±å®šä¹‰
 ```
 è¿™é‡Œæˆ‘ä»¬é…ç½®äº†FORWARD_KEYä¸º`fk-******`, é‚£ä¹ˆåé¢å®¢æˆ·ç«¯åœ¨è°ƒç”¨æ—¶åªéœ€è®¾ç½®OPENAI_API_KEYä¸ºæˆ‘ä»¬è‡ªå®šä¹‰çš„`fk-******` å³å¯ã€‚  
 è¿™æ ·çš„å¥½å¤„æ˜¯åœ¨ä½¿ç”¨ä¸€äº›éœ€è¦è¾“å…¥OPENAI_API_KEYçš„ç¬¬ä¸‰æ–¹åº”ç”¨æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨`fk-******`æ­é…proxyä½¿ç”¨ï¼ˆå¦‚ä¸‹é¢çš„ä¾‹å­ï¼‰ è€Œæ— éœ€æ‹…å¿ƒOPENAI_API_KEYè¢«æ³„éœ²ã€‚
 
 **ç”¨ä¾‹:**
 ```bash
-curl https://caloi.top/openai/v1/chat/completions \
+curl https://api.openai-forward.top/v1/chat/completions \
   -H "Content-Type: application/json" \
-  -H "Authorization: Bearer fk-mytoken-abcd" \
+  -H "Authorization: Bearer fk-******" \
   -d '{
     "model": "gpt-3.5-turbo",
     "messages": [{"role": "user", "content": "Hello!"}]
   }'
 ```
 **Python**
 ```diff
   import openai
-+ openai.api_base = "https://caloi.top/openai/v1"
++ openai.api_base = "https://api.openai-forward.top/v1"
 - openai.api_key = "sk-******"
 + openai.api_key = "fk-******"
 ```
 **Web application**
 ```bash 
 docker run -d \
     -p 3000:3000 \
     -e OPENAI_API_KEY="fk-******" \
-    -e BASE_URL="caloi.top/openai" \
+    -e BASE_URL="https://api.openai-forward.top" \
     -e CODE="<your password>" \
     yidadaa/chatgpt-next-web 
 ``` 
 
-# Backer and Sponsor
+## èŠå¤©æ—¥å¿—
+
+ä¿å­˜è·¯å¾„åœ¨å½“å‰ç›®å½•ä¸‹çš„`Log/`è·¯å¾„ä¸­ã€‚  
+èŠå¤©æ—¥å¿—ä»¥ `chat_`å¼€å¤´, é»˜è®¤æ¯5è½®å¯¹è¯å†™å…¥ä¸€æ¬¡æ–‡ä»¶    
+è®°å½•æ ¼å¼ä¸º
+
+```text
+{'host': xxx, 'model': xxx, 'message': [{'user': xxx}, {'assistant': xxx}]}
+{'assistant': xxx}
+
+{'host': ...}
+{'assistant': ...}
+
+...
+```
+
+## Backer and Sponsor
 
 <a href="https://www.jetbrains.com/?from=beidongjiedeguang/openai-forward" target="_blank">
-<img src="./img/jetbrains.svg" width="100px" height="100px">
+<img src=".github/images/jetbrains.svg" width="100px" height="100px">
 </a>
 
-# License
+## License
 
 Openai-forward is licensed under the [MIT](https://opensource.org/license/mit/) license.
```

#### html2text {}

```diff
@@ -1,92 +1,101 @@
+Metadata-Version: 2.1 Name: openai_forward Version: 0.2.0 Summary: Ã°ÂŸÂšÂ€ Openai
+api forward Ã‚Â· OpenAI Ã¦ÂÂ¥Ã¥ÂÂ£Ã¨Â½Â¬Ã¥ÂÂ‘Ã¦ÂœÂÃ¥ÂŠÂ¡ Ã‚Â· stream forwarding Project-URL:
+Homepage, https://github.com/beidongjiedeguang/openai-forward Project-URL:
+Documentation, https://github.com/beidongjiedeguang/openai-forward#openai-
+forward Project-URL: Issues, https://github.com/beidongjiedeguang/openai-
+forward/issues Project-URL: Source, https://github.com/beidongjiedeguang/
+openai-forward Author-email: kunyuan
+gmail.com> License-Expression: MIT License-File: LICENSE Keywords: OpenAI API
+Forwarding,chatgpt,fastapi,httpx,openai,openai-api,openai-
+proxy,python,streaming-api Classifier: Development Status :: 5 - Production/
+Stable Classifier: Operating System :: OS Independent Classifier: Programming
+Language :: Python :: 3 Requires-Python: >=3.6 Requires-Dist: fastapi Requires-
+Dist: httpx Requires-Dist: loguru Requires-Dist: orjson Requires-Dist: python-
+dotenv Requires-Dist: pytz Requires-Dist: sparrow-python>=0.1.3 Requires-Dist:
+uvicorn Provides-Extra: bard Requires-Dist: googlebard; extra == 'bard'
+Provides-Extra: chatgpt Requires-Dist: revchatgpt; extra == 'chatgpt' Provides-
+Extra: edge Requires-Dist: edgegpt; extra == 'edge' Provides-Extra: ssl
+Requires-Dist: certbot; extra == 'ssl' Description-Content-Type: text/markdown
 **Ã¤Â¸Â­Ã¦Â–Â‡** | [**English**](./README_EN.md)
                                     ******
                                 OpenAI Forward
                                      ******
                         OpenAI API Ã¦ÂÂ¥Ã¥ÂÂ£Ã¨Â½Â¬Ã¥ÂÂ‘Ã¦ÂœÂÃ¥ÂŠÂ¡
                 The fastest way to deploy openai api forwarding
  [PyPI_version] [License] [Release_(latest_by_date)] [GitHub_repo_size] [docer
                 image_size] [tests] [pypi_downloads] [codecov]
 Ã¦ÂœÂ¬Ã©Â¡Â¹Ã§Â›Â®Ã§Â”Â¨Ã¤ÂºÂÃ¨Â§Â£Ã¥Â†Â³Ã¤Â¸Â€Ã¤ÂºÂ›Ã¥ÂœÂ°Ã¥ÂŒÂºÃ¦Â—Â Ã¦Â³Â•Ã§Â›Â´Ã¦ÂÂ¥Ã¨Â®Â¿Ã©Â—Â®OpenAIÃ§ÂšÂ„Ã©Â—Â®Ã©Â¢Â˜Ã¯Â¼ÂŒÃ¥Â°Â†Ã¨Â¯Â¥Ã¦ÂœÂÃ¥ÂŠÂ¡Ã©ÂƒÂ¨Ã§Â½Â²Ã¥ÂœÂ¨Ã¥ÂÂ¯Ã¤Â»Â¥Ã¦Â­Â£Ã¥Â¸Â¸Ã¨Â®Â¿Ã©Â—Â®openai
 apiÃ§ÂšÂ„Ã¦ÂœÂÃ¥ÂŠÂ¡Ã¥Â™Â¨Ã¤Â¸ÂŠÃ¯Â¼ÂŒÃ©Â€ÂšÃ¨Â¿Â‡Ã¨Â¯Â¥Ã¦ÂœÂÃ¥ÂŠÂ¡Ã¨Â½Â¬Ã¥ÂÂ‘OpenAIÃ§ÂšÂ„Ã¨Â¯Â·Ã¦Â±Â‚Ã£Â€Â‚Ã¥ÂÂ³Ã¦ÂÂ­Ã¥Â»ÂºÃ¥ÂÂÃ¥ÂÂ‘Ã¤Â»Â£Ã§ÂÂ†Ã¦ÂœÂÃ¥ÂŠÂ¡
---- Ã¦ÂµÂ‹Ã¨Â¯Â•Ã¨Â®Â¿Ã©Â—Â®Ã¯Â¼Âšhttps://caloi.top/openai/v1/chat/completions Ã¦ÂˆÂ–Ã¨Â€Â…Ã¨Â¯Â´
-https://caloi.top/openai Ã§Â­Â‰Ã¤Â»Â·Ã¤ÂºÂ https://api.openai.com --- # Ã§Â›Â®Ã¥Â½Â• -
-[Ã¥ÂŠÂŸÃ¨ÂƒÂ½](#Ã¥ÂŠÂŸÃ¨ÂƒÂ½) - [Ã¥ÂºÂ”Ã§Â”Â¨](#Ã¥ÂºÂ”Ã§Â”Â¨) - [Ã¥Â®Â‰Ã¨Â£Â…Ã©ÂƒÂ¨Ã§Â½Â²](#Ã¥Â®Â‰Ã¨Â£Â…Ã©ÂƒÂ¨Ã§Â½Â²) -
-[Ã¦ÂœÂÃ¥ÂŠÂ¡Ã¨Â°ÂƒÃ§Â”Â¨](#Ã¦ÂœÂÃ¥ÂŠÂ¡Ã¨Â°ÂƒÃ§Â”Â¨) - [Ã©Â…ÂÃ§Â½Â®Ã©Â€Â‰Ã©Â¡Â¹](#Ã©Â…ÂÃ§Â½Â®Ã©Â€Â‰Ã©Â¡Â¹) - [Ã¨ÂÂŠÃ¥Â¤Â©Ã¦Â—Â¥Ã¥Â¿Â—]
-(#Ã¨ÂÂŠÃ¥Â¤Â©Ã¦Â—Â¥Ã¥Â¿Â—) - [Ã©Â«Â˜Ã§ÂºÂ§Ã©Â…ÂÃ§Â½Â®](#Ã©Â«Â˜Ã§ÂºÂ§Ã©Â…ÂÃ§Â½Â®) # Ã¥ÂŠÂŸÃ¨ÂƒÂ½ **Ã¥ÂŸÂºÃ§Â¡Â€Ã¥ÂŠÂŸÃ¨ÂƒÂ½** - [x]
+--- Ã§Â”Â±Ã¦ÂœÂ¬Ã©Â¡Â¹Ã§Â›Â®Ã¦ÂÂ­Ã¥Â»ÂºÃ§ÂšÂ„Ã©Â•Â¿Ã¦ÂœÂŸÃ¤Â»Â£Ã§ÂÂ†Ã¥ÂœÂ°Ã¥ÂÂ€Ã¯Â¼Âš > https://api.openai-forward.top
+## Ã§Â›Â®Ã¥Â½Â• - [Ã¥ÂŠÂŸÃ¨ÂƒÂ½](#Ã¥ÂŠÂŸÃ¨ÂƒÂ½) - [Ã©ÂƒÂ¨Ã§Â½Â²Ã¦ÂŒÂ‡Ã¥ÂÂ—](#Ã©ÂƒÂ¨Ã§Â½Â²Ã¦ÂŒÂ‡Ã¥ÂÂ—) - [Ã¥ÂºÂ”Ã§Â”Â¨]
+(#Ã¥ÂºÂ”Ã§Â”Â¨) - [Ã©Â…ÂÃ§Â½Â®Ã©Â€Â‰Ã©Â¡Â¹](#Ã©Â…ÂÃ§Â½Â®Ã©Â€Â‰Ã©Â¡Â¹) - [Ã¨ÂÂŠÃ¥Â¤Â©Ã¦Â—Â¥Ã¥Â¿Â—](#Ã¨ÂÂŠÃ¥Â¤Â©Ã¦Â—Â¥Ã¥Â¿Â—) -
+[Ã©Â«Â˜Ã§ÂºÂ§Ã©Â…ÂÃ§Â½Â®](#Ã©Â«Â˜Ã§ÂºÂ§Ã©Â…ÂÃ§Â½Â®) ## Ã¥ÂŠÂŸÃ¨ÂƒÂ½ **Ã¥ÂŸÂºÃ§Â¡Â€Ã¥ÂŠÂŸÃ¨ÂƒÂ½** - [x]
 Ã¦Â”Â¯Ã¦ÂŒÂÃ¨Â½Â¬Ã¥ÂÂ‘OpenAIÃ¦Â‰Â€Ã¦ÂœÂ‰Ã¦ÂÂ¥Ã¥ÂÂ£ - [x] Ã¦Â”Â¯Ã¦ÂŒÂÃ¦ÂµÂÃ¥Â¼ÂÃ¥Â“ÂÃ¥ÂºÂ” - [x]
-Ã¦Â”Â¯Ã¦ÂŒÂÃ¦ÂŒÂ‡Ã¥Â®ÂšÃ¨Â½Â¬Ã¥ÂÂ‘Ã¨Â·Â¯Ã§Â”Â±Ã¥Â‰ÂÃ§Â¼Â€ - [x] dockerÃ©ÂƒÂ¨Ã§Â½Â² - [x] pip Ã¥Â®Â‰Ã¨Â£Â…Ã©ÂƒÂ¨Ã§Â½Â²
+Ã¦Â”Â¯Ã¦ÂŒÂÃ¦ÂŒÂ‡Ã¥Â®ÂšÃ¨Â½Â¬Ã¥ÂÂ‘Ã¨Â·Â¯Ã§Â”Â±Ã¥Â‰ÂÃ§Â¼Â€ - [x] dockerÃ©ÂƒÂ¨Ã§Â½Â² - [x] pip Ã¥Â®Â‰Ã¨Â£Â…Ã©ÂƒÂ¨Ã§Â½Â² - [x]
+vercel Ã¤Â¸Â€Ã©Â”Â®Ã¤Â¸ÂªÃ¤ÂºÂºÃ¥Â…ÂÃ¨Â´Â¹Ã©ÂƒÂ¨Ã§Â½Â² [![Deploy with Vercel](https://vercel.com/
+button)](https://vercel.com/new/clone?repository-
+url=https%3A%2F%2Fgithub.com%2Fbeidongjiedeguang%2Fopenai-forward&project-
+name=openai-forward&repository-name=openai-forward&framework=other)
 **Ã©Â«Â˜Ã§ÂºÂ§Ã¥ÂŠÂŸÃ¨ÂƒÂ½** - [x] Ã¥Â®ÂÃ¦Â—Â¶Ã¨Â®Â°Ã¥Â½Â•Ã¨ÂÂŠÃ¥Â¤Â©Ã¨Â®Â°Ã¥Â½Â•
-(Ã¥ÂŒÂ…Ã¦Â‹Â¬Ã¦ÂµÂÃ¥Â¼ÂÃ¥Â“ÂÃ¥ÂºÂ”Ã§ÂšÂ„Ã¨ÂÂŠÃ¥Â¤Â©Ã¥Â†Â…Ã¥Â®Â¹) - [x] Ã¦Â”Â¯Ã¦ÂŒÂÃ©Â»Â˜Ã¨Â®Â¤openai api key(Ã¥Â¤Âšapi key
-Ã¥Â¾ÂªÃ§ÂÂ¯Ã¨Â°ÂƒÃ§Â”Â¨) - [x] Ã¨Â‡ÂªÃ¥Â®ÂšÃ¤Â¹Â‰forward api key Ã¤Â»Â£Ã¦Â›Â¿ openai api key
-(Ã¨Â§ÂÃ©Â«Â˜Ã§ÂºÂ§Ã©Â…ÂÃ§Â½Â®) - [x] Ã¦Â”Â¯Ã¦ÂŒÂÃ¨Â¯Â·Ã¦Â±Â‚IPÃ©ÂªÂŒÃ¨Â¯Â(IPÃ§Â™Â½Ã¥ÂÂÃ¥ÂÂ•Ã¤Â¸ÂÃ©Â»Â‘Ã¥ÂÂÃ¥ÂÂ•) # Ã¥ÂºÂ”Ã§Â”Â¨
-> Ã¨Â¿Â™Ã©Â‡ÂŒÃ¤Â»Â¥Ã¤Â¸ÂªÃ¤ÂºÂºÃ¤Â½Â¿Ã§Â”Â¨Ã¨Â¯Â¥Ã©Â¡Â¹Ã§Â›Â®Ã¦ÂÂ­Ã¥Â»ÂºÃ¥Â¥Â½Ã§ÂšÂ„Ã¤Â»Â£Ã§ÂÂ†Ã¦ÂœÂÃ¥ÂŠÂ¡ https://caloi.top/
-openai Ã¤Â¸ÂºÃ¤Â¾Â‹ ### [caloi.top](https://caloi.top) Ã¥ÂŸÂºÃ¤ÂºÂÃ¥Â¼Â€Ã¦ÂºÂÃ©Â¡Â¹Ã§Â›Â®[ChatGPT-
-Next-Web](https://github.com/Yidadaa/ChatGPT-Next-
-Web)Ã¦ÂÂ­Ã¥Â»ÂºÃ¨Â‡ÂªÃ¥Â·Â±Ã§ÂšÂ„chatgptÃ¦ÂœÂÃ¥ÂŠÂ¡ Ã¦Â›Â¿Ã¦ÂÂ¢dockerÃ¥ÂÂ¯Ã¥ÂŠÂ¨Ã¥Â‘Â½Ã¤Â»Â¤Ã¤Â¸Â­Ã§ÂšÂ„
+(Ã¥ÂŒÂ…Ã¦Â‹Â¬Ã¦ÂµÂÃ¥Â¼ÂÃ¥Â“ÂÃ¥ÂºÂ”Ã§ÂšÂ„Ã¨ÂÂŠÃ¥Â¤Â©Ã¥Â†Â…Ã¥Â®Â¹) - [x] Ã¥Â…ÂÃ¨Â®Â¸Ã¨Â¾Â“Ã¥Â…Â¥Ã¥Â¤ÂšÃ¤Â¸Âªopenai api key
+Ã§Â»Â„Ã¦ÂˆÂÃ¨Â½Â®Ã¨Â¯Â¢Ã¦Â±Â  - [x] Ã¨Â‡ÂªÃ¥Â®ÂšÃ¤Â¹Â‰ api key (Ã¨Â§ÂÃ©Â«Â˜Ã§ÂºÂ§Ã©Â…ÂÃ§Â½Â®) - [x]
+Ã¦Â”Â¯Ã¦ÂŒÂÃ¨Â¯Â·Ã¦Â±Â‚IPÃ©ÂªÂŒÃ¨Â¯Â(IPÃ§Â™Â½Ã¥ÂÂÃ¥ÂÂ•Ã¤Â¸ÂÃ©Â»Â‘Ã¥ÂÂÃ¥ÂÂ•) ## Ã©ÂƒÂ¨Ã§Â½Â²Ã¦ÂŒÂ‡Ã¥ÂÂ—
+Ã¦ÂÂÃ¤Â¾Â›Ã¤Â¸Â‰Ã§Â§ÂÃ©ÂƒÂ¨Ã§Â½Â²Ã¦Â–Â¹Ã¥Â¼Â 1. [vps + pip Ã¥Â®Â‰Ã¨Â£Â…Ã©ÂƒÂ¨Ã§Â½Â²](deploy.md#pip-Ã¦ÂÂ¨Ã¨ÂÂ)
+(Ã¦ÂÂ¨Ã¨ÂÂ) 2. [vps + Docker](deploy.md#docker-Ã¦ÂÂ¨Ã¨ÂÂ) (Ã¦ÂÂ¨Ã¨ÂÂ) > https://
+api.openai-forward.top 3. [Ã¤Â¸Â€Ã©Â”Â®VercelÃ©ÂƒÂ¨Ã§Â½Â²](deploy.md#vercel-Ã¤Â¸Â€Ã©Â”Â®Ã©ÂƒÂ¨Ã§Â½Â²) >
+https://vercel.openai-forward.top ## Ã¥ÂºÂ”Ã§Â”Â¨ ### [Ã¨ÂÂŠÃ¥Â¤Â©Ã¥ÂºÂ”Ã§Â”Â¨](https://
+chat.beidongjiedeguang.top) Ã¥ÂŸÂºÃ¤ÂºÂÃ¥Â¼Â€Ã¦ÂºÂÃ©Â¡Â¹Ã§Â›Â®[ChatGPT-Next-Web](https://
+github.com/Yidadaa/ChatGPT-Next-Web)Ã¦ÂÂ­Ã¥Â»ÂºÃ¨Â‡ÂªÃ¥Â·Â±Ã§ÂšÂ„chatgptÃ¦ÂœÂÃ¥ÂŠÂ¡
+Ã¦Â›Â¿Ã¦ÂÂ¢dockerÃ¥ÂÂ¯Ã¥ÂŠÂ¨Ã¥Â‘Â½Ã¤Â»Â¤Ã¤Â¸Â­Ã§ÂšÂ„
 `BASE_URL`Ã¤Â¸ÂºÃ¦ÂˆÂ‘Ã¤Â»Â¬Ã¨Â‡ÂªÃ¥Â·Â±Ã¦ÂÂ­Ã¥Â»ÂºÃ§ÂšÂ„Ã¤Â»Â£Ã§ÂÂ†Ã¦ÂœÂÃ¥ÂŠÂ¡Ã¥ÂœÂ°Ã¥ÂÂ€ ```bash docker run -d \ -
-p 3000:3000 \ -e OPENAI_API_KEY="sk-******" \ -e BASE_URL="caloi.top/openai" \
--e CODE="" \ yidadaa/chatgpt-next-web ``` Ã¨Â®Â¿Ã©Â—Â® https://caloi.top
-Ã£Â€Â‚Ã¨Â®Â¿Ã©Â—Â®Ã¥Â¯Â†Ã§Â ÂÃ¤Â¸Âº `beidongjiedeguang` ### Ã¥ÂœÂ¨Ã¦Â¨Â¡Ã¥ÂÂ—Ã¤Â¸Â­Ã¤Â½Â¿Ã§Â”Â¨ **JS/TS** ```diff
-import { Configuration } from "openai"; const configuration = new Configuration
-({ + basePath: "https://caloi.top/openai/v1", apiKey: "sk-******", }); ```
-**Python** ```diff import openai + openai.api_base = "https://caloi.top/openai/
-v1" openai.api_key = "sk-******" ``` ### Image Generation (DALL-E): ```bash
-curl --location 'https://caloi.top/openai/v1/images/generations' \ --header
-'Authorization: Bearer sk-******' \ --header 'Content-Type: application/json' \
---data '{ "prompt": "A photo of a cat", "n": 1, "size": "512x512" }' ``` #
-Ã¥Â®Â‰Ã¨Â£Â…Ã©ÂƒÂ¨Ã§Â½Â² Ã©Â€Â‰Ã¦Â‹Â©Ã¤Â¸Â€Ã§Â§ÂÃ¥ÂÂ³Ã¥ÂÂ¯ ## pip **Ã¥Â®Â‰Ã¨Â£Â…** ```bash pip install openai-
-forward ``` **Ã¨Â¿ÂÃ¨Â¡ÂŒÃ¨Â½Â¬Ã¥ÂÂ‘Ã¦ÂœÂÃ¥ÂŠÂ¡** Ã¥ÂÂ¯Ã©Â€ÂšÃ¨Â¿Â‡`--
-port`Ã¦ÂŒÂ‡Ã¥Â®ÂšÃ§Â«Â¯Ã¥ÂÂ£Ã¥ÂÂ·Ã¯Â¼ÂŒÃ©Â»Â˜Ã¨Â®Â¤Ã¤Â¸Âº`8000` ```bash openai_forward run --port=9999
-``` Ã¦ÂœÂÃ¥ÂŠÂ¡Ã¥Â°Â±Ã¦ÂÂ­Ã¥Â»ÂºÃ¥Â®ÂŒÃ¦ÂˆÂÃ¤ÂºÂ†Ã¯Â¼ÂŒÃ¤Â½Â¿Ã§Â”Â¨Ã¦Â–Â¹Ã¥Â¼ÂÃ¥ÂÂªÃ©ÂœÂ€Ã¥Â°Â†`https://api.openai.com`
-Ã¦Â›Â¿Ã¦ÂÂ¢Ã¤Â¸ÂºÃ¦ÂœÂÃ¥ÂŠÂ¡Ã¦Â‰Â€Ã¥ÂœÂ¨Ã§Â«Â¯Ã¥ÂÂ£`http://{ip}:{port}` Ã¥ÂÂ³Ã¥ÂÂ¯Ã£Â€Â‚ Ã¥Â½Â“Ã§Â„Â¶Ã¤Â¹ÂŸÃ¥ÂÂ¯Ã¤Â»Â¥Ã¥Â°Â†
-OPENAI_API_KEY Ã¤Â½ÂœÃ¤Â¸ÂºÃ§ÂÂ¯Ã¥Â¢ÂƒÃ¥ÂÂ˜Ã©Â‡ÂÃ¦ÂˆÂ–`--api_key`Ã¥ÂÂ‚Ã¦Â•Â°Ã¤Â¼Â Ã¥Â…Â¥Ã¤Â½ÂœÃ¤Â¸ÂºÃ©Â»Â˜Ã¨Â®Â¤api
-keyÃ¯Â¼ÂŒ
-Ã¨Â¿Â™Ã¦Â Â·Ã¥Â®Â¢Ã¦ÂˆÂ·Ã§Â«Â¯Ã¥ÂœÂ¨Ã¨Â¯Â·Ã¦Â±Â‚Ã§Â›Â¸Ã¥Â…Â³Ã¨Â·Â¯Ã§Â”Â±Ã¦Â—Â¶Ã¥ÂÂ¯Ã¤Â»Â¥Ã¦Â—Â Ã©ÂœÂ€Ã¥ÂœÂ¨HeaderÃ¤Â¸Â­Ã¤Â¼Â Ã¥Â…Â¥AuthorizationÃ£Â€Â‚
-Ã¥Â¸Â¦Ã©Â»Â˜Ã¨Â®Â¤api keyÃ§ÂšÂ„Ã¥ÂÂ¯Ã¥ÂŠÂ¨Ã¦Â–Â¹Ã¥Â¼ÂÃ¯Â¼Âš ```bash openai_forward run --port=9999 --
-api_key="sk-******" ``` Ã¦Â³Â¨: Ã¥Â¦Â‚Ã¦ÂÂœÃ¦Â—Â¢Ã¥Â­Â˜Ã¥ÂœÂ¨Ã©Â»Â˜Ã¨Â®Â¤api
-keyÃ¥ÂÂˆÃ¥ÂœÂ¨Ã¨Â¯Â·Ã¦Â±Â‚Ã¥Â¤Â´Ã¤Â¸Â­Ã¤Â¼Â Ã¥Â…Â¥Ã¤ÂºÂ†api keyÃ¯Â¼ÂŒÃ¥ÂˆÂ™Ã¤Â»Â¥Ã¨Â¯Â·Ã¦Â±Â‚Ã¥Â¤Â´Ã¤Â¸Â­Ã§ÂšÂ„api
-keyÃ¤Â¼ÂšÃ¨Â¦Â†Ã§Â›Â–Ã©Â»Â˜Ã¨Â®Â¤api key. ## Docker (Ã¦ÂÂ¨Ã¨ÂÂ) ```bash docker run -d -p 9999:
-8000 beidongjiedeguang/openai-forward:latest ```
-Ã¥Â°Â†Ã¦Â˜Â Ã¥Â°Â„Ã¥Â®Â¿Ã¤Â¸Â»Ã¦ÂœÂºÃ§ÂšÂ„9999Ã§Â«Â¯Ã¥ÂÂ£Ã¯Â¼ÂŒÃ©Â€ÂšÃ¨Â¿Â‡`http://{ip}:9999`Ã¨Â®Â¿Ã©Â—Â®Ã¦ÂœÂÃ¥ÂŠÂ¡Ã£Â€Â‚
-Ã¦Â³Â¨Ã¯Â¼ÂšÃ¥ÂÂŒÃ¦Â Â·Ã¥ÂÂ¯Ã¤Â»Â¥Ã¥ÂœÂ¨Ã¥ÂÂ¯Ã¥ÂŠÂ¨Ã¥Â‘Â½Ã¤Â»Â¤Ã¤Â¸Â­Ã©Â€ÂšÃ¨Â¿Â‡-
-eÃ¤Â¼Â Ã¥Â…Â¥Ã§ÂÂ¯Ã¥Â¢ÂƒÃ¥ÂÂ˜Ã©Â‡ÂOPENAI_API_KEY=sk-xxxÃ¤Â½ÂœÃ¤Â¸ÂºÃ©Â»Â˜Ã¨Â®Â¤api key ## Ã¦ÂºÂÃ§Â ÂÃ©ÂƒÂ¨Ã§Â½Â²
-```bash git clone https://github.com/beidongjiedeguang/openai-forward.git --
-depth=1 cd openai-forward ``` **Docker** ```bash docker-compose up ``` **pip**
-```bash pip install -e . openai-forward run ``` # Ã¦ÂœÂÃ¥ÂŠÂ¡Ã¨Â°ÂƒÃ§Â”Â¨
-Ã¦Â›Â¿Ã¦ÂÂ¢openaiÃ§ÂšÂ„apiÃ¥ÂœÂ°Ã¥ÂÂ€Ã¤Â¸ÂºÃ¨Â¯Â¥Ã¦ÂœÂÃ¥ÂŠÂ¡Ã§ÂšÂ„Ã¥ÂœÂ°Ã¥ÂÂ€Ã¥ÂÂ³Ã¥ÂÂ¯Ã¯Â¼ÂŒÃ¥Â¦Â‚Ã¯Â¼Âš ```bash https://
-api.openai.com/v1/chat/completions ``` Ã¦Â›Â¿Ã¦ÂÂ¢Ã¤Â¸Âº ```bash http://{ip}:{port}/v1/
-chat/completions ``` # Ã©Â…ÂÃ§Â½Â®Ã©Â€Â‰Ã©Â¡Â¹ **`openai-forward run`Ã¥ÂÂ‚Ã¦Â•Â°Ã©Â…ÂÃ§Â½Â®Ã©Â¡Â¹** |
-Ã©Â…ÂÃ§Â½Â®Ã©Â¡Â¹ | Ã¨Â¯Â´Ã¦Â˜Â | Ã©Â»Â˜Ã¨Â®Â¤Ã¥Â€Â¼ | |-----------| --- | :---: | | --port |
-Ã¦ÂœÂÃ¥ÂŠÂ¡Ã§Â«Â¯Ã¥ÂÂ£Ã¥ÂÂ· | 8000 | | --workers | Ã¥Â·Â¥Ã¤Â½ÂœÃ¨Â¿Â›Ã§Â¨Â‹Ã¦Â•Â° | 1 |
-**Ã§ÂÂ¯Ã¥Â¢ÂƒÃ¥ÂÂ˜Ã©Â‡ÂÃ©Â…ÂÃ§Â½Â®Ã©Â¡Â¹** Ã¦Â”Â¯Ã¦ÂŒÂÃ¤Â»ÂÃ¨Â¿ÂÃ¨Â¡ÂŒÃ§Â›Â®Ã¥Â½Â•Ã¤Â¸Â‹Ã§ÂšÂ„`.env`Ã¦Â–Â‡Ã¤Â»Â¶Ã¤Â¸Â­Ã¨Â¯Â»Ã¥ÂÂ–: |
-Ã§ÂÂ¯Ã¥Â¢ÂƒÃ¥ÂÂ˜Ã©Â‡Â | Ã¨Â¯Â´Ã¦Â˜Â | Ã©Â»Â˜Ã¨Â®Â¤Ã¥Â€Â¼ | |-----------------|------------------------
------------------------------------------|:------------------------:| |
-OPENAI_API_KEY | Ã©Â»Â˜Ã¨Â®Â¤openai api keyÃ¯Â¼ÂŒÃ¦Â”Â¯Ã¦ÂŒÂÃ¥Â¤ÂšÃ¤Â¸ÂªÃ©Â»Â˜Ã¨Â®Â¤api key, Ã¤Â»Â¥ `sk-
-` Ã¥Â¼Â€Ã¥Â¤Â´Ã¯Â¼ÂŒ Ã¤Â»Â¥Ã§Â©ÂºÃ¦Â Â¼Ã¥ÂˆÂ†Ã¥Â‰Â² | Ã¦Â—Â  | | FORWARD_KEY |
-Ã¥Â…ÂÃ¨Â®Â¸Ã¨Â°ÂƒÃ§Â”Â¨Ã¦Â–Â¹Ã¤Â½Â¿Ã§Â”Â¨Ã¨Â¯Â¥keyÃ¤Â»Â£Ã¦Â›Â¿openai api keyÃ¯Â¼ÂŒÃ¦Â”Â¯Ã¦ÂŒÂÃ¥Â¤ÂšÃ¤Â¸Âªforward key,
-Ã¤Â»Â¥`fk-` Ã¥Â¼Â€Ã¥Â¤Â´, Ã¤Â»Â¥Ã§Â©ÂºÃ¦Â Â¼Ã¥ÂˆÂ†Ã¥Â‰Â² | Ã¦Â—Â  | | OPENAI_BASE_URL | Ã¨Â½Â¬Ã¥ÂÂ‘base url |
-`https://api.openai.com` | | LOG_CHAT | Ã¦Â˜Â¯Ã¥ÂÂ¦Ã¨Â®Â°Ã¥Â½Â•Ã¨ÂÂŠÃ¥Â¤Â©Ã¥Â†Â…Ã¥Â®Â¹ | `true` | |
-ROUTE_PREFIX | Ã¨Â·Â¯Ã§Â”Â±Ã¥Â‰ÂÃ§Â¼Â€ | Ã¦Â—Â  | | IP_WHITELIST | ipÃ§Â™Â½Ã¥ÂÂÃ¥ÂÂ•, Ã§Â©ÂºÃ¦Â Â¼Ã¥ÂˆÂ†Ã¥Â¼Â€
-| Ã¦Â—Â  | | IP_BLACKLIST | ipÃ©Â»Â‘Ã¥ÂÂÃ¥ÂÂ•, Ã§Â©ÂºÃ¦Â Â¼Ã¥ÂˆÂ†Ã¥Â¼Â€ | Ã¦Â—Â  | # Ã¨ÂÂŠÃ¥Â¤Â©Ã¦Â—Â¥Ã¥Â¿Â—
-Ã¤Â¿ÂÃ¥Â­Â˜Ã¨Â·Â¯Ã¥Â¾Â„Ã¥ÂœÂ¨Ã¥Â½Â“Ã¥Â‰ÂÃ§Â›Â®Ã¥Â½Â•Ã¤Â¸Â‹Ã§ÂšÂ„`Log/`Ã¨Â·Â¯Ã¥Â¾Â„Ã¤Â¸Â­Ã£Â€Â‚ Ã¨ÂÂŠÃ¥Â¤Â©Ã¦Â—Â¥Ã¥Â¿Â—Ã¤Â»Â¥
-`chat_`Ã¥Â¼Â€Ã¥Â¤Â´, Ã©Â»Â˜Ã¨Â®Â¤Ã¦Â¯Â5Ã¨Â½Â®Ã¥Â¯Â¹Ã¨Â¯ÂÃ¥Â†Â™Ã¥Â…Â¥Ã¤Â¸Â€Ã¦Â¬Â¡Ã¦Â–Â‡Ã¤Â»Â¶ Ã¨Â®Â°Ã¥Â½Â•Ã¦Â Â¼Ã¥Â¼ÂÃ¤Â¸Âº ```text
-{'host': xxx, 'model': xxx, 'message': [{'user': xxx}, {'assistant': xxx}]}
-{'assistant': xxx} {'host': ...} {'assistant': ...} ... ``` # Ã©Â«Â˜Ã§ÂºÂ§Ã©Â…ÂÃ§Â½Â®
-**Ã¨Â®Â¾Ã§Â½Â®api_keyÃ¤Â¸ÂºÃ¨Â‡ÂªÃ¥Â·Â±Ã¨Â®Â¾Ã§Â½Â®Ã§ÂšÂ„forward key** Ã©ÂœÂ€Ã¨Â¦ÂÃ©Â…ÂÃ§Â½Â® OPENAI_API_KEY Ã¥Â’ÂŒ
-FORWARD_KEY, Ã¤Â¾Â‹Ã¥Â¦Â‚ ```bash OPENAI_API_KEY=sk-******* FORWARD_KEY=fk-****** #
-Ã¨Â¿Â™Ã©Â‡ÂŒfk-tokenÃ§Â”Â±Ã¦ÂˆÂ‘Ã¤Â»Â¬Ã¨Â‡ÂªÃ¥Â·Â±Ã¥Â®ÂšÃ¤Â¹Â‰ ``` Ã¨Â¿Â™Ã©Â‡ÂŒÃ¦ÂˆÂ‘Ã¤Â»Â¬Ã©Â…ÂÃ§Â½Â®Ã¤ÂºÂ†FORWARD_KEYÃ¤Â¸Âº`fk-
-******`,
+p 3000:3000 \ -e OPENAI_API_KEY="sk-******" \ -e BASE_URL="https://api.openai-
+forward.top" \ -e CODE="kunyuan" \ yidadaa/chatgpt-next-web ```
+Ã¨Â¿Â™Ã©Â‡ÂŒÃ©ÂƒÂ¨Ã§Â½Â²Ã¤ÂºÂ†Ã¤Â¸Â€Ã¤Â¸ÂªÃ¯Â¼ÂŒÃ¤Â¾Â›Ã¥Â¤Â§Ã¥Â®Â¶Ã¨Â½Â»Ã¥ÂºÂ¦Ã¤Â½Â¿Ã§Â”Â¨: https://
+chat.beidongjiedeguang.top , Ã¨Â®Â¿Ã©Â—Â®Ã¥Â¯Â†Ã§Â Â: `kunyuan` ### Ã¥ÂœÂ¨Ã¤Â»Â£Ã§Â ÂÃ¤Â¸Â­Ã¤Â½Â¿Ã§Â”Â¨
+**JS/TS** ```diff import { Configuration } from "openai"; const configuration =
+new Configuration({ + basePath: "https://api.openai-forward.top/v1", apiKey:
+"sk-******", }); ``` **Python** ```diff import openai + openai.api_base =
+"https://api.openai-forward.top/v1" openai.api_key = "sk-******" ``` **gpt-3.5-
+turbo** ```bash curl https://api.openai-forward.top/v1/chat/completions \ -
+H "Content-Type: application/json" \ -H "Authorization: Bearer sk-******" \ -
+d '{ "model": "gpt-3.5-turbo", "messages": [{"role": "user", "content":
+"Hello!"}] }' ``` **Image Generation (DALL-E)** ```bash curl --location 'https:
+//api.openai-forward.top/v1/images/generations' \ --header 'Authorization:
+Bearer sk-******' \ --header 'Content-Type: application/json' \ --data '
+{ "prompt": "A photo of a cat", "n": 1, "size": "512x512" }' ``` ##
+Ã©Â…ÂÃ§Â½Â®Ã©Â€Â‰Ã©Â¡Â¹ **`openai-forward run`Ã¥ÂÂ‚Ã¦Â•Â°Ã©Â…ÂÃ§Â½Â®Ã©Â¡Â¹** | Ã©Â…ÂÃ§Â½Â®Ã©Â¡Â¹ | Ã¨Â¯Â´Ã¦Â˜Â |
+Ã©Â»Â˜Ã¨Â®Â¤Ã¥Â€Â¼ | |-----------| --- | :---: | | --port | Ã¦ÂœÂÃ¥ÂŠÂ¡Ã§Â«Â¯Ã¥ÂÂ£Ã¥ÂÂ· | 8000 | | -
+-workers | Ã¥Â·Â¥Ã¤Â½ÂœÃ¨Â¿Â›Ã§Â¨Â‹Ã¦Â•Â° | 1 | Ã¦Â›Â´Ã¥Â¤ÂšÃ¥ÂÂ‚Ã¦Â•Â° `openai-forward run --help`
+Ã¦ÂŸÂ¥Ã§ÂœÂ‹ **Ã§ÂÂ¯Ã¥Â¢ÂƒÃ¥ÂÂ˜Ã©Â‡ÂÃ©Â…ÂÃ§Â½Â®Ã©Â¡Â¹**
+Ã¦Â”Â¯Ã¦ÂŒÂÃ¤Â»ÂÃ¨Â¿ÂÃ¨Â¡ÂŒÃ§Â›Â®Ã¥Â½Â•Ã¤Â¸Â‹Ã§ÂšÂ„`.env`Ã¦Â–Â‡Ã¤Â»Â¶Ã¤Â¸Â­Ã¨Â¯Â»Ã¥ÂÂ–: | Ã§ÂÂ¯Ã¥Â¢ÂƒÃ¥ÂÂ˜Ã©Â‡Â | Ã¨Â¯Â´Ã¦Â˜Â |
+Ã©Â»Â˜Ã¨Â®Â¤Ã¥Â€Â¼ | |-----------------|------------------------------------------------
+-----------------|:------------------------:| | OPENAI_API_KEY | Ã©Â»Â˜Ã¨Â®Â¤openai
+api keyÃ¯Â¼ÂŒÃ¦Â”Â¯Ã¦ÂŒÂÃ¥Â¤ÂšÃ¤Â¸ÂªÃ©Â»Â˜Ã¨Â®Â¤api key, Ã¤Â»Â¥ `sk-` Ã¥Â¼Â€Ã¥Â¤Â´Ã¯Â¼ÂŒ Ã¤Â»Â¥Ã§Â©ÂºÃ¦Â Â¼Ã¥ÂˆÂ†Ã¥Â‰Â² | Ã¦Â—Â 
+| | FORWARD_KEY | Ã¥Â…ÂÃ¨Â®Â¸Ã¨Â°ÂƒÃ§Â”Â¨Ã¦Â–Â¹Ã¤Â½Â¿Ã§Â”Â¨Ã¨Â¯Â¥keyÃ¤Â»Â£Ã¦Â›Â¿openai api
+keyÃ¯Â¼ÂŒÃ¦Â”Â¯Ã¦ÂŒÂÃ¥Â¤ÂšÃ¤Â¸Âªforward key, Ã¤Â»Â¥`fk-` Ã¥Â¼Â€Ã¥Â¤Â´, Ã¤Â»Â¥Ã§Â©ÂºÃ¦Â Â¼Ã¥ÂˆÂ†Ã¥Â‰Â² | Ã¦Â—Â  | |
+OPENAI_BASE_URL | Ã¨Â½Â¬Ã¥ÂÂ‘base url | `https://api.openai.com` | | LOG_CHAT |
+Ã¦Â˜Â¯Ã¥ÂÂ¦Ã¨Â®Â°Ã¥Â½Â•Ã¨ÂÂŠÃ¥Â¤Â©Ã¥Â†Â…Ã¥Â®Â¹ | `true` | | ROUTE_PREFIX | Ã¨Â·Â¯Ã§Â”Â±Ã¥Â‰ÂÃ§Â¼Â€ | Ã¦Â—Â  | |
+IP_WHITELIST | ipÃ§Â™Â½Ã¥ÂÂÃ¥ÂÂ•, Ã§Â©ÂºÃ¦Â Â¼Ã¥ÂˆÂ†Ã¥Â¼Â€ | Ã¦Â—Â  | | IP_BLACKLIST | ipÃ©Â»Â‘Ã¥ÂÂÃ¥ÂÂ•,
+Ã§Â©ÂºÃ¦Â Â¼Ã¥ÂˆÂ†Ã¥Â¼Â€ | Ã¦Â—Â  | ## Ã©Â«Â˜Ã§ÂºÂ§Ã©Â…ÂÃ§Â½Â® **Ã¨Â®Â¾Ã§Â½Â®api_keyÃ¤Â¸ÂºÃ¨Â‡ÂªÃ¥Â·Â±Ã¨Â®Â¾Ã§Â½Â®Ã§ÂšÂ„forward
+key** Ã©ÂœÂ€Ã¨Â¦ÂÃ©Â…ÂÃ§Â½Â® OPENAI_API_KEY Ã¥Â’ÂŒ FORWARD_KEY, Ã¤Â¾Â‹Ã¥Â¦Â‚ ```bash
+OPENAI_API_KEY=sk-******* FORWARD_KEY=fk-****** # Ã¨Â¿Â™Ã©Â‡ÂŒfk-
+tokenÃ§Â”Â±Ã¦ÂˆÂ‘Ã¤Â»Â¬Ã¨Â‡ÂªÃ¥Â·Â±Ã¥Â®ÂšÃ¤Â¹Â‰ ``` Ã¨Â¿Â™Ã©Â‡ÂŒÃ¦ÂˆÂ‘Ã¤Â»Â¬Ã©Â…ÂÃ§Â½Â®Ã¤ÂºÂ†FORWARD_KEYÃ¤Â¸Âº`fk-******`,
 Ã©Â‚Â£Ã¤Â¹ÂˆÃ¥ÂÂÃ©ÂÂ¢Ã¥Â®Â¢Ã¦ÂˆÂ·Ã§Â«Â¯Ã¥ÂœÂ¨Ã¨Â°ÂƒÃ§Â”Â¨Ã¦Â—Â¶Ã¥ÂÂªÃ©ÂœÂ€Ã¨Â®Â¾Ã§Â½Â®OPENAI_API_KEYÃ¤Â¸ÂºÃ¦ÂˆÂ‘Ã¤Â»Â¬Ã¨Â‡ÂªÃ¥Â®ÂšÃ¤Â¹Â‰Ã§ÂšÂ„`fk-
 ******` Ã¥ÂÂ³Ã¥ÂÂ¯Ã£Â€Â‚
 Ã¨Â¿Â™Ã¦Â Â·Ã§ÂšÂ„Ã¥Â¥Â½Ã¥Â¤Â„Ã¦Â˜Â¯Ã¥ÂœÂ¨Ã¤Â½Â¿Ã§Â”Â¨Ã¤Â¸Â€Ã¤ÂºÂ›Ã©ÂœÂ€Ã¨Â¦ÂÃ¨Â¾Â“Ã¥Â…Â¥OPENAI_API_KEYÃ§ÂšÂ„Ã§Â¬Â¬Ã¤Â¸Â‰Ã¦Â–Â¹Ã¥ÂºÂ”Ã§Â”Â¨Ã¦Â—Â¶Ã¯Â¼ÂŒÃ¦ÂˆÂ‘Ã¤Â»Â¬Ã¥ÂÂ¯Ã¤Â»Â¥Ã¤Â½Â¿Ã§Â”Â¨`fk-
 ******`Ã¦ÂÂ­Ã©Â…ÂproxyÃ¤Â½Â¿Ã§Â”Â¨Ã¯Â¼ÂˆÃ¥Â¦Â‚Ã¤Â¸Â‹Ã©ÂÂ¢Ã§ÂšÂ„Ã¤Â¾Â‹Ã¥Â­ÂÃ¯Â¼Â‰
 Ã¨Â€ÂŒÃ¦Â—Â Ã©ÂœÂ€Ã¦Â‹Â…Ã¥Â¿ÂƒOPENAI_API_KEYÃ¨Â¢Â«Ã¦Â³Â„Ã©ÂœÂ²Ã£Â€Â‚ **Ã§Â”Â¨Ã¤Â¾Â‹:** ```bash curl https://
-caloi.top/openai/v1/chat/completions \ -H "Content-Type: application/json" \ -
-H "Authorization: Bearer fk-mytoken-abcd" \ -d '{ "model": "gpt-3.5-turbo",
+api.openai-forward.top/v1/chat/completions \ -H "Content-Type: application/
+json" \ -H "Authorization: Bearer fk-******" \ -d '{ "model": "gpt-3.5-turbo",
 "messages": [{"role": "user", "content": "Hello!"}] }' ``` **Python** ```diff
-import openai + openai.api_base = "https://caloi.top/openai/v1" -
+import openai + openai.api_base = "https://api.openai-forward.top/v1" -
 openai.api_key = "sk-******" + openai.api_key = "fk-******" ``` **Web
 application** ```bash docker run -d \ -p 3000:3000 \ -e OPENAI_API_KEY="fk-
-******" \ -e BASE_URL="caloi.top/openai" \ -e CODE="" \ yidadaa/chatgpt-next-
-web ``` # Backer and Sponsor [./img/jetbrains.svg] # License Openai-forward is
-licensed under the [MIT](https://opensource.org/license/mit/) license.
+******" \ -e BASE_URL="https://api.openai-forward.top" \ -e CODE="" \ yidadaa/
+chatgpt-next-web ``` ## Ã¨ÂÂŠÃ¥Â¤Â©Ã¦Â—Â¥Ã¥Â¿Â— Ã¤Â¿ÂÃ¥Â­Â˜Ã¨Â·Â¯Ã¥Â¾Â„Ã¥ÂœÂ¨Ã¥Â½Â“Ã¥Â‰ÂÃ§Â›Â®Ã¥Â½Â•Ã¤Â¸Â‹Ã§ÂšÂ„`Log/
+`Ã¨Â·Â¯Ã¥Â¾Â„Ã¤Â¸Â­Ã£Â€Â‚ Ã¨ÂÂŠÃ¥Â¤Â©Ã¦Â—Â¥Ã¥Â¿Â—Ã¤Â»Â¥ `chat_`Ã¥Â¼Â€Ã¥Â¤Â´,
+Ã©Â»Â˜Ã¨Â®Â¤Ã¦Â¯Â5Ã¨Â½Â®Ã¥Â¯Â¹Ã¨Â¯ÂÃ¥Â†Â™Ã¥Â…Â¥Ã¤Â¸Â€Ã¦Â¬Â¡Ã¦Â–Â‡Ã¤Â»Â¶ Ã¨Â®Â°Ã¥Â½Â•Ã¦Â Â¼Ã¥Â¼ÂÃ¤Â¸Âº ```text {'host': xxx,
+'model': xxx, 'message': [{'user': xxx}, {'assistant': xxx}]} {'assistant':
+xxx} {'host': ...} {'assistant': ...} ... ``` ## Backer and Sponsor [.github/
+images/jetbrains.svg] ## License Openai-forward is licensed under the [MIT]
+(https://opensource.org/license/mit/) license.
```

### Comparing `openai_forward-0.1.9/pyproject.toml` & `openai_forward-0.2.0/pyproject.toml`

 * *Files 22% similar despite different names*

```diff
@@ -4,17 +4,18 @@
 
 [project]
 name = "openai_forward"
 description = "ğŸš€ Openai api forward Â· OpenAI æ¥å£è½¬å‘æœåŠ¡ Â· stream forwarding"
 authors = [
     { name = "kunyuan", email = "beidongjiedeguang@gmail.com" },
 ]
+license = "MIT"
 requires-python = ">=3.6"
 readme = "README.md"
-keywords = ["openai", "chatgpt", "openai-api", "openai-proxy", "forward", "streaming-api", "fastapi", "python"]
+keywords = ["openai", "chatgpt", "openai-api", "openai-proxy", "OpenAI API Forwarding", "streaming-api", "fastapi", "python", "httpx"]
 classifiers = [
     "Development Status :: 5 - Production/Stable",
     "Operating System :: OS Independent",
     "Programming Language :: Python :: 3"
 ]
 
 dependencies = [
@@ -22,15 +23,14 @@
     "sparrow-python>=0.1.3",
     "fastapi",
     "uvicorn",
     "orjson",
     "python-dotenv",
     "httpx",
     "pytz",
-    "chardet",
 ]
 
 dynamic = ["version"]
 
 [project.urls]
 Homepage = "https://github.com/beidongjiedeguang/openai-forward"
 Documentation = "https://github.com/beidongjiedeguang/openai-forward#openai-forward"
```

